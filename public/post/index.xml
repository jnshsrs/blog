<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Science, Physiotherapy and Stats</title>
    <link>/post/</link>
    <description>Recent content in Posts on Science, Physiotherapy and Stats</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>&amp;copy; &lt;a href=&#34;https://github.com/jnshsrs&#34;&gt;Jens Hüsers&lt;/a&gt; 2018</copyright>
    <lastBuildDate>Sat, 19 Jan 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Finalizing a Glmnet Model: An Example using Credit Data</title>
      <link>/post/2019-01-25-finalizing-glmnet-models/</link>
      <pubDate>Sat, 19 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019-01-25-finalizing-glmnet-models/</guid>
      <description>Evaluating a models hyperparameter In machine learning we develop algorithms to map from predictive variables to an output variable which we wish to predict using unseen data. When building models we can use hyperparameters of the algorithms to increase model performance.
An example is lasso regression which, very briefly, puts a constraint on the models coefficient in order to decrease variance of model coefcients and coeficient selection.
To figure out the appropriate hyperparameters cross-validation is applied, where cross-validation is a method to simulate the models performance using test and a training sets.</description>
    </item>
    
    <item>
      <title>Koeffizienten des Bass-Models</title>
      <link>/post/estimating-the-bass-model/</link>
      <pubDate>Wed, 07 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/estimating-the-bass-model/</guid>
      <description>Untersuchung von Innovationen Vor dem Hintergrund immer schneller verlaufender Innovationszyklen und der zunehmenden Digitalisierung sind Modelle die versuchen Innovationsmechanismen zu erklären von großem Interesse. Obwohl die Innovationsforschung, die sich mit diesem Thema befasst, heutzutage einen großen Stellenwert einnummt, befassten sich Forscher um 1960 mit der Thematik. Insbesondere Rogers und Bass befassten sich der Erklärung und Modellierung von Innovationen. Bass gelang es als Erster ein mathematisches Model zur Erklärung von Innovationen und der Produktentwicklung zu erstellen, die ursprünglich von Rogers in seiner “Diffusion of Innovation Theory” aufgestellt wurden.</description>
    </item>
    
    <item>
      <title>Marktentwicklung von Innovationen</title>
      <link>/post/marktentwicklung-von-innovationen/</link>
      <pubDate>Wed, 07 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/marktentwicklung-von-innovationen/</guid>
      <description>Dazu kann auf Grundlage des Modells zusätzlich geschätzt werden, wie sich die Produktentwicklung am Marktniederschlägt.
Es ist jedoch zu beachten, dass es sich bei diesen Modellen im Wesentlichen um eine Vereinfachung der komplexen Marktrealität handelt. Zudem werden die Prognosen auf Basis der Marktverhältnisse der Vergangenheit getroffen. Verändern sich diese Verhältnisse ist das Modell nicht mehr statthaft, da es diese Veränderungen nicht modellieren kann. Dies ist jedoch ein Problem vieler Vorhersagemodelle und gilt nicht exklusiv für das Bass-Modell.</description>
    </item>
    
    <item>
      <title>HL7 FHIR Fundamentals - Creating an Observation Resource</title>
      <link>/post/hl7-fhir-fundamentale-create-an-observation-resource/</link>
      <pubDate>Tue, 06 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/hl7-fhir-fundamentale-create-an-observation-resource/</guid>
      <description>In the last post I talked about the central FHIR resource Patient which captures all the information of a patient, such as name, date of birth and so forth. Another important resource it Observation. This resource is used to give details about a specific observation such as blood pressure or heart rate. According to the specification, we use the element code which has the datatype CodeableConcept. We can use Terminologies like LOINC or SNOMED CT to specifiy the observation type.</description>
    </item>
    
    <item>
      <title>HL7 FHIR Fundamentals - Creating Resources</title>
      <link>/post/hl-fhir-fundamentale-creating-resources/</link>
      <pubDate>Mon, 05 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/hl-fhir-fundamentale-creating-resources/</guid>
      <description>FHIR Fundamentals Class On November 1st 2018 I started an online course on the HL7 FHIR Standard. This course is offerd by the HL7 which is an international organization for standardization in healthcare and it is all about the latest standard called Fast Healthcare Interoperablity Resources or short: FHIR.
This standard used RESTful services and json or xml-documents to transfer information.
As the name FHIR suggests this standard is all about resources which are the main building blocks in FHIR to capture information.</description>
    </item>
    
    <item>
      <title>Exploring the Cost Function of Logistic Regression</title>
      <link>/post/exploring-the-cost-function-of-logistic-regression/</link>
      <pubDate>Sun, 14 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/exploring-the-cost-function-of-logistic-regression/</guid>
      <description>This post is about exploring the cost function and its connection to the logistic regression function.
knitr::opts_chunk$set(echo = TRUE, warning=F, message=FALSE, fig.align=&amp;#39;center&amp;#39;) library(tidyverse) library(plotly) library(latex2exp) I want to get a deeper understanding of the connection between the logistic regresssion and its cost function. Therefore I created a function in R and conducted a grid approximation with this function. The results are presented below.
The logistic regression can be applied to data where the dependent variable is coded binary where the referent class is coded as a 1 and as 0 otherwise.</description>
    </item>
    
    <item>
      <title>GMDS Tutorium 2018 - Datenvisualisierung in R mit ggplot2</title>
      <link>/post/gmds-tutorium-2018-datenvisualisierung-in-r-mit-ggplot2/</link>
      <pubDate>Thu, 06 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/gmds-tutorium-2018-datenvisualisierung-in-r-mit-ggplot2/</guid>
      <description>Dieses Dokument enthält die Aufgaben zu meinem Tutorial “Datenvisualisierung in R mit ggplot2” auf der 63. Jahrestagung der GMDS am 6. September 2018 in Osnabrück.
Die Präsentation zum Workshop sind hier zu finden. Das Repository mit den Dateien sind hier zu finden.
  Setup Laden der benötigten R-Pakete für dieses Tutorium.
# laden von ggplot2 library(ggplot2) # Wir können ggplot2 auch mit dem tidyverse Paket laden # In dem Fall werden weitere Pakete des wie z.</description>
    </item>
    
    <item>
      <title>GMDS Tutorium 2018 - Der Einstieg in die Programmiersprache R</title>
      <link>/post/r-tutorium-gmds-2018/</link>
      <pubDate>Thu, 06 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/r-tutorium-gmds-2018/</guid>
      <description>Preface Dieser Post enthält das Skript sowie die Aufgaben inklusive Lösungen meines Tutoriums “Einstieg in die Programmiersprache R” auf der 63. Jahrestagung der GMDS e.V. in Osnabrück am 6.9.2018. Das Skript mit den Aufgaben ohne Lösungen sind in der Datei workbook-rstats-gmds18-aufgaben.Rmd auf Github verfügbar.
Installation In diesem Kurs werden wir mit R und RStudio als Programmierumgebung (IDE) arbeiten. Beide Programme stehen kostenlos zur Verfügung.
Zunächst muss die Programmiersprache R installiert werden.</description>
    </item>
    
    <item>
      <title>Join by rows</title>
      <link>/post/join-by-rows/</link>
      <pubDate>Fri, 03 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/join-by-rows/</guid>
      <description>In a recent project I find myself often in the situation to deal with similar but not equal datasets. I am working with the German Hospital Registers for the years since 2005 and there is a dataset for each year.
Some of them share the same information stored in columns and I had to combine them in a single dataframe.
library(tidyverse)  ## ── Attaching packages ────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.</description>
    </item>
    
    <item>
      <title>Import ordered SPSS factors into R</title>
      <link>/post/import-ordered-spss-factors-into-r/</link>
      <pubDate>Wed, 18 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/import-ordered-spss-factors-into-r/</guid>
      <description>SPSS Factor Variables Recently I have to work with data stored in SPSS files, most variables stored as ordered factor variables. Since I work with R, I have to import them. On the one hand, fortunatly, there is the haven package, which makes importing SPSS files an easy taks. On the other hand, unfortunatly, ordered factors are imported as integer values which are not associated with the corresponding factor label. In consequence, it is very hard to tell what a integer value of a factor variable means.</description>
    </item>
    
  </channel>
</rss>